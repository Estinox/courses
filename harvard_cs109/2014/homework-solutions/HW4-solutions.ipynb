{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Can you predict the Midterm Elections?\n",
    "\n",
    "Due: Monday, November 3, 2014 11:59 PM\n",
    "\n",
    "<a href=https://raw.githubusercontent.com/cs109/2014/master/homework/HW4.ipynb download=HW4.ipynb> Download this assignment</a>\n",
    "\n",
    "#### Submission Instructions\n",
    "To submit your homework, create a folder named lastname_firstinitial_hw# and place your IPython notebooks, data files, and any other files in this folder. Your IPython Notebooks should be completely executed with the results visible in the notebook. We should not have to run any code. Compress the folder (please use .zip compression) and submit to the CS109 dropbox in the appropriate folder. If we cannot access your work because these directions are not followed correctly, we will not grade your work. For the competition (problem 4), we will post a link on Piazza to a Google Form for you to submit your predictions. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Add Introduction**\n",
    "\n",
    "You will use the [HuffPost Pollster API](http://elections.huffingtonpost.com/pollster/api) to extract the polls for the current 2014 Senate Midterm Elections and provide a final prediction of the result of each state.\n",
    "\n",
    "#### Data\n",
    "\n",
    "We will use the polls from the [2014 Senate Midterm Elections](http://elections.huffingtonpost.com/pollster) from the [HuffPost Pollster API](http://elections.huffingtonpost.com/pollster/api). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "import requests \n",
    "from StringIO import StringIO\n",
    "import numpy as np\n",
    "import pandas as pd # pandas\n",
    "import matplotlib.pyplot as plt # module for plotting \n",
    "import datetime as dt # module for manipulating dates and times\n",
    "import numpy.linalg as lin # module for performing linear algebra operations\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# special matplotlib argument for improved plots\n",
    "from matplotlib import rcParams\n",
    "\n",
    "#colorbrewer2 Dark2 qualitative color table\n",
    "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
    "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
    "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
    "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
    "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
    "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
    "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843)]\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['figure.dpi'] = 150\n",
    "rcParams['axes.color_cycle'] = dark2_colors\n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['font.size'] = 14\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['patch.facecolor'] = dark2_colors[0]\n",
    "rcParams['font.family'] = 'StixGeneral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Data Wrangling\n",
    "\n",
    "We will read in the polls from the [2014 Senate Midterm Elections](http://elections.huffingtonpost.com/pollster) from the [HuffPost Pollster API](http://elections.huffingtonpost.com/pollster/api) and create a dictionary of DataFrames as well a master table information for each race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(a)\n",
    "\n",
    "Read in [this JSON object](http://elections.huffingtonpost.com/pollster/api/charts/?topic=2014-senate) containing the polls for the 2014 Senate Elections using the HuffPost API. Call this JSON object `info`.  This JSON object is imported as a list in Python where each element contains the information for one race.  Use the function `type` to confirm the that `info` is a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###\n",
    "url_str = \"http://elections.huffingtonpost.com/pollster/api/charts/?topic=2014-senate\"\n",
    "info = requests.get(url_str).json()\n",
    "type(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(b)\n",
    "\n",
    "For each element of the list in `info` extract the state. We should have one poll per state, but we do not. Why?\n",
    "\n",
    "**Hint**: Use the internet to find out information on the races in each state that has more than one entry. Eliminate entries of the list that represent races that are not happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use a list comprehension to extract the `state` from each race. Then, we use the python module `collections.Counter` to determine which states have multiple races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states = [str(election['state']) for election in info]\n",
    "titles = [str(election['title']) for election in info]\n",
    "\n",
    "countStates = collections.Counter(states)\n",
    "print countStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twoPollIndex = [elem[0] for elem in countStates.most_common(4)]\n",
    "twoPollIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print all the titles of each state with more than one race and use google to find out more information about each race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for state in twoPollIndex:\n",
    "    ind = [i for i, x in enumerate(states) if x == state]\n",
    "    for elem in ind:\n",
    "        print \"title: %s (index: %g)\" % (titles[elem], elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **\n",
    "\n",
    "Using some [google-fu](http://www.urbandictionary.com/define.php?term=google-fu), we see the races in Oklahoma and South Carolina are special elections. In Georgia, we should remove the senate runoff races and in New Hampshire, we see Bass withdrew so we will take out both of these races from our `info` JSON object.  The indices in the `info` list is 6 and 36. Therefore, we will remove these indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "removeset = set([6, 36])\n",
    "infoClean = [v for i, v in enumerate(info) if i not in removeset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(c)\n",
    "\n",
    "Create a dictionary of pandas DataFrames called `polls` keyed by the name of the election (a string). Each value in the dictionary should contain the polls for one of the races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###\n",
    "election_urls = [election['url'] + '.csv' for election in infoClean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a dictionary of pandas DataFrames that will be keyed by the name of the election (a string), we use the following function `build_frame` introduced in [Homework 2](http://nbviewer.ipython.org/github/cs109/2014/blob/master/homework/HW2.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_frame(url):\n",
    "    \"\"\"\n",
    "    Returns a pandas DataFrame object containing\n",
    "    the data returned from the given url\n",
    "    \"\"\"\n",
    "    source = requests.get(url).text\n",
    "    \n",
    "    # Use StringIO because pd.DataFrame.from_csv requires .read() method\n",
    "    s = StringIO(source)\n",
    "    \n",
    "    return pd.DataFrame.from_csv(s, index_col=None).convert_objects(\n",
    "            convert_dates=\"coerce\", convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Makes a dictionary of pandas DataFrames keyed on election string.\n",
    "polls = dict((election['slug'], build_frame(election['url']+'.csv')) for election in infoClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dfs` dictionary contains a set of key-value pairs where the `key` is string of the election and the value is a pandas DataFrame with the polls for one 2014 Senate race. We can print the first few keys of the `dfs` dictionary using `keys()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "polls.keys()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(d)\n",
    "\n",
    "Now create a master table information containing information about each race. Create a pandas DataFrame called `candidates` with rows containing information about each race. The `candidates` DataFrame should have the following columns: \n",
    "\n",
    "1. `State` = the state where the race is being held\n",
    "2. `R` = name of republican candidate\n",
    "3. `D` = name of non-republican candidate (Democrate or Independent) \n",
    "4. `incumbent` = R, D or NA\n",
    "\n",
    "**Hint**: You will need a considerable amount of data wrangling for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###\n",
    "rows = []\n",
    "\n",
    "for i,dt in enumerate(infoClean):\n",
    "    x = dt['estimates'][0:2]\n",
    "    if not x[0]['last_name']:\n",
    "        tmp = dt['url'].split('-')+['vs']\n",
    "        j = tmp.index('vs')\n",
    "        if j!=len(tmp)-1:\n",
    "            R = tmp[j-1].capitalize()\n",
    "            D = tmp[j+1].capitalize()\n",
    "            incumbent = np.nan\n",
    "            #if no data means race is decided\n",
    "    else:\n",
    "        tmp = [x[0]['party'],x[1]['party']]\n",
    "        R = x[tmp.index('Rep')]['last_name']\n",
    "        idx = [k for k in range(len(tmp)) if tmp[k]!='Rep'][0]\n",
    "        D = x[idx]['last_name']\n",
    "        tmp2 = [x[0]['incumbent'],x[1]['incumbent']]\n",
    "        tmp2+=[True]\n",
    "        incumbent = np.nan\n",
    "        if tmp2.index(True)!=2:\n",
    "            incumbent = tmp[tmp2.index(True)]\n",
    "            \n",
    "    rows.append((dt['state'], R, D, incumbent))\n",
    "    \n",
    "candidates = pd.DataFrame(rows, columns=[\"State\", \"R\", \"D\", \"incumbent\"])\n",
    "        \n",
    "#remove second last name \n",
    "candidates.R = [candidate.split(' ')[-1] for candidate in candidates.R]\n",
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Confidence Intervals\n",
    "\n",
    "Compute a 99% confidence interval for each state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(a)\n",
    "\n",
    "Assume you have $M$ polls with sample sizes $n_1, \\dots, n_M$. If the polls are independent, what is the average of the variances of each poll if the true proportion is $p$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **\n",
    "\n",
    "The variance of a single poll with sample $n_i$ is $Var(X_i) = \\frac{p(1-p)}{n_i}$. Therefore, the average of the variances across $M$ polls is\n",
    "\n",
    "$$ \\frac{1}{M} \\sum_{i=1}^M Var( {X}_i) = \\frac{1}{M} p(1-p)(1/n_1 + \\dots +1/n_M) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(b)\n",
    "\n",
    "Compute the square root of these values in Problem 2(a) for the republican candidates in each race. Then, compute the standard deviations of the observed poll results for each race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def calc_sds(infoClean, polls, numdays=None):\n",
    "    theo_sds = []\n",
    "    obs_sds = []\n",
    "    npolls = []\n",
    "    for ii,election in enumerate(infoClean):\n",
    "        #Note that the `polls` dictionary does not have a guaranteed ordering\n",
    "        #because Python dictionaries are unordered object. For this reason, we\n",
    "        #need to be careful and use the ordered `infoClean` object to make sure we\n",
    "        #are correctly aligning the elements of `polls` and the rows in `candidates`.\n",
    "        polls_key = election['slug']\n",
    "        this_election = polls[polls_key]\n",
    "        \n",
    "        #Optional argument to filter on age of polls.\n",
    "        if numdays is not None:\n",
    "            monthdiff = this_election['End Date'].apply(lambda x: (datetime.datetime.now()-x).days)\n",
    "            this_election = this_election.ix[monthdiff <= numdays,:]\n",
    "            \n",
    "        npoll = this_election.shape[0]\n",
    "\n",
    "        #Use the candidates dataframe to find the name of the Republican in this race.\n",
    "        #Use this to grab the column of polling results for this candidate.\n",
    "        #Put poll results onto the proportion (not percentage) scale\n",
    "        p = this_election[candidates.R.ix[ii]]/100\n",
    "        n = this_election[\"Number of Observations\"]\n",
    "\n",
    "        #Theoretical sd assumes a common value of p across all polls. Use the mean.\n",
    "        p_mean = np.mean(p)\n",
    "        theo_sd = np.sqrt(p_mean*(1-p_mean)*np.mean(1./n))\n",
    "\n",
    "        #Observed sd is a simple calculation.\n",
    "        obs_sd = np.std(p)\n",
    "\n",
    "        theo_sds.append(theo_sd)\n",
    "        obs_sds.append(obs_sd)\n",
    "        npolls.append(npoll)\n",
    "        \n",
    "    return (theo_sds, obs_sds, npolls)\n",
    "\n",
    "theo, obs, npolls = calc_sds(infoClean, polls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(c) \n",
    "\n",
    "Plot observed versus theoretical (average of the theoretical SDs) with the area of the point proportional to number of polls. How do these compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grab the poll count from the infoClean object.\n",
    "plt.scatter(theo, obs, marker=\"o\", s=npolls*10)\n",
    "plt.xlabel(\"Theoretical Standard Deviation\")\n",
    "plt.ylabel(\"Observed Standard Deviation\")\n",
    "plt.title(\"Observed vs Theoretical Polling SD's\")\n",
    "\n",
    "currentx = plt.xlim()\n",
    "currenty = plt.ylim()\n",
    "plt.plot((0,1),(0,1), c='black', linewidth=1)\n",
    "plt.xlim(currentx)\n",
    "plt.ylim(currenty)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **\n",
    "\n",
    "Observed sd's are much larger than theoretical sd's. The overshoot is particularly large when there are large numbers of polls, suggesting that there is variation between pollsters that is not explained by the theoretical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(d)\n",
    "\n",
    "Repeat Problem 2(c) but include only the most recent polls from the last two months. Do they match better or worse or the same? Can we just trust the theoretical values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###\n",
    "# Use the `calc_sds` optional argument to filter on number of days.\n",
    "# Filter to 60 days.\n",
    "\n",
    "theo, obs, npolls = calc_sds(infoClean, polls, 60)\n",
    "plt.scatter(theo, obs, marker=\"o\", s=npolls*10)\n",
    "plt.xlabel(\"Theoretical Standard Deviation\")\n",
    "plt.ylabel(\"Observed Standard Deviation\")\n",
    "plt.title(\"Observed vs Theoretical Polling SD's, Last 60 days\")\n",
    "\n",
    "currentx = plt.xlim()\n",
    "currenty = plt.ylim()\n",
    "plt.plot((0,1),(0,1), c='black', linewidth=1)\n",
    "plt.xlim(currentx)\n",
    "plt.ylim(currenty)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **\n",
    "\n",
    "The gap between theoretical and observed does not seem to decrease as we focus on more recent polls. This suggests that the excess variation in the data with respect to the theoretical model is not explained by opinion shifts over time. It is more likely that this is due to differences between pollsters, which are time-invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(e)\n",
    "\n",
    "Create a scatter plot with each point representing one state. Is there one or more races that are outlier in that it they have much larger variabilities than expected? Explore the original poll data and explain why the discrepancy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###\n",
    "#Compute the standard deviations on the full data again.\n",
    "theo, obs, npolls = calc_sds(infoClean, polls)\n",
    "\n",
    "#This time, do the scatterplot using text labels on each datapoint.\n",
    "plt.scatter(theo, obs, marker=\"o\", s=0)\n",
    "plt.xlabel(\"Theoretical Standard Deviation\")\n",
    "plt.ylabel(\"Observed Standard Deviation\")\n",
    "plt.title(\"Observed vs Theoretical Polling SD's\")\n",
    "\n",
    "for i in range(len(theo)):\n",
    "    plt.text(theo[i], obs[i], candidates.ix[i,'State'])\n",
    "\n",
    "currentx = plt.xlim()\n",
    "currenty = plt.ylim()\n",
    "plt.plot((0,1),(0,1), c='black', linewidth=1)\n",
    "plt.xlim(currentx)\n",
    "plt.ylim(currenty)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **\n",
    "\n",
    "Texas appears to be the biggest outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(f)\n",
    "\n",
    "Construct confidence intervals for the difference in each race. Use either theoretical or data driven estimates of the standard error depending on your answer to this question. Use the results in Problem 2(e), to justify your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###\n",
    "# this is mean +- 2.58 SD also save this results to candidate df\n",
    "def calc_diffs(infoClean, polls, numdays=None):\n",
    "    rows = []\n",
    "    for ii,election in enumerate(infoClean):\n",
    "        #Note that the `polls` dictionary does not have a guaranteed ordering\n",
    "        #because Python dictionaries are unordered object. For this reason, we\n",
    "        #need to be careful and use the ordered `infoClean` object to make sure we\n",
    "        #are correctly aligning the elements of `polls` and the rows in `candidates`.\n",
    "        polls_key = election['slug']\n",
    "        this_election = polls[polls_key]\n",
    "            \n",
    "        npoll = this_election.shape[0]\n",
    "\n",
    "        #Use the candidates dataframe to find the name of the Republican in this race.\n",
    "        #Use this to grab the column of polling results for this candidate.\n",
    "        #Put poll results onto the proportion (not percentage) scale\n",
    "        diffs = (this_election[candidates.R.ix[ii]]-this_election[candidates.D.ix[ii]])/100\n",
    "        \n",
    "        mean_diff = np.mean(diffs)\n",
    "        obs_se = np.std(diffs)/np.sqrt(npoll)\n",
    "        \n",
    "        rows.append((polls_key, mean_diff, obs_se, mean_diff-obs_se*2.58, mean_diff+obs_se*2.58))\n",
    "\n",
    "    return rows\n",
    "\n",
    "ests = pd.DataFrame(calc_diffs(infoClean, polls), columns=['race', 'mean', 'se', 'lower', 'upper'])\n",
    "print \"Unsorted:\"\n",
    "print ests[['race', 'lower', 'upper']]\n",
    "ests.sort(\"mean\", inplace=True)\n",
    "print \"Sorted:\"\n",
    "print ests[['race', 'lower', 'upper']]\n",
    "\n",
    "plt.errorbar(range(ests.shape[0]), ests['mean'], yerr=ests['se']*2.58, fmt='o')\n",
    "plt.xticks(range(ests.shape[0]), ests['race'].values, rotation=90)\n",
    "plt.xlim(-1, ests.shape[0])\n",
    "plt.axhline(0, linewidth=1, color='black')\n",
    "plt.xlabel(\"Race\")\n",
    "plt.ylabel(\"Difference\")\n",
    "plt.title(\"99% Confidence intervals for Diff (Rep-Dem) for each race\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Prediction and Posterior Probabilities\n",
    "\n",
    "Perform a Bayesian analysis to predict the probability of Republicans winning in each state then provide a posterior distribution of the number of republicans in the senate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3(a)\n",
    "\n",
    "First, we define a Bayesian model for each race. The prior for the difference $\\theta$ between republicans and democtrats will be $N(\\mu,\\tau^2)$. Say before seeing poll data you have no idea who is going to win, what should $\\mu$ be? How about $\\tau$, should it be large or small? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **\n",
    "Because we have no prior idea who will win, the prior mean $\\mu$ should be 0. And again we don't know anything about the data, but we know that the difference should not be very large. So $\\tau$ should be small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3(b)\n",
    "\n",
    "What is the distribution of $d$ conditioned on $\\theta$. What is the posterior distribution of $\\theta | d$? \n",
    "\n",
    "**Hint**: Use normal approximation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "\n",
    "$d \\mid \\theta \\sim N(\\theta, \\sigma^2/M)$. We assume that $\\sigma^2$ is known based on the observed sample variance, and $M$ is the number of polls averaged together to obtain $d$.\n",
    "\n",
    "$\\theta \\mid d \\sim N\\left(B\\mu + (1-B)d, (1-B)\\sigma^2/M\\right)$, where $B = \\frac{1/\\tau^2}{M/\\sigma^2 + 1/\\tau^2}$. (Note that there are lots of equivalent ways to write $B$, but this one shows that it is a *precision weight*, based on the ratio of the prior precision to the total precision of the prior and the data. Precision here is the inverse of the variance).\n",
    "\n",
    "Equivalently, $\\theta | d$ is $\\theta | d \\sim N( B \\mu + (1-B) d, 1/(M/\\sigma^2 + 1/ \\tau^2))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3(c)\n",
    "\n",
    "The prior represents what we think before hand. We do not know who is expected to win, so we assume $\\mu=0$. For this problem estimate $\\tau$ using the observed differences across states (Hint: $\\tau$ represents the standard deviation of a typical difference). Compute the posterior mean for each state and plot it against original average. Is there much change? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###\n",
    "# A cheap but slightly biased way to estimate tau is to take the\n",
    "# standard deviation of the state polling means.\n",
    "# Use `ests` from last question.\n",
    "tau = np.std(ests['mean'])\n",
    "B = (1/tau**2)/(1/ests['se']**2+1/tau**2)\n",
    "ests['mu_post'] = (1-B)*ests['mean']\n",
    "\n",
    "plt.scatter(ests['mean'], ests['mu_post'], s=50)\n",
    "plt.title(\"Bayes vs. Raw Poll Averages\")\n",
    "plt.xlabel(\"Raw Average\")\n",
    "plt.ylabel(\"Bayes\")\n",
    "\n",
    "currentx = plt.xlim()\n",
    "currenty = plt.ylim()\n",
    "plt.plot((-1,1),(-1,1), c='black', linewidth=1)\n",
    "plt.xlim(currentx)\n",
    "plt.ylim(currenty)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "\n",
    "Because there are a lot of datapoints (i.e. a lot of polls), $\\sigma^2/M$ is much smaller than $\\tau^2$, which results in a very small shrinkage factor for each datapoint (most elements of $B$ are extremely small). When you have this much data, the data largely overwhelms the prior. We do see that in those cases where the estimates are moved by the prior, they are pulled closer to zero than their raw average, resulting in a slope slightly shallower than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3(d)\n",
    "\n",
    "For each state, report a probabilty of Republicans winning. How does your answer here compare to the other aggregators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###\n",
    "#First, compute a standard deviation for each poll\n",
    "ests['sd_post'] = np.sqrt((1-B)*ests['se']**2)\n",
    "\n",
    "#Now, use normal CDF to find the posterior probability that the difference is greater than zero.\n",
    "import scipy.stats\n",
    "ests['R_win_prob'] = 1-scipy.stats.norm.cdf(0, loc=ests['mu_post'], scale=ests['sd_post'])\n",
    "print ests[['race','R_win_prob']].sort('R_win_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "\n",
    "As expected from other aggregators, only a few states have outcomes that seem uncertain. Our model seems to be more certain about these tossup races than most aggregators. For us, the states that are less than 99% leaning one way or the other are IA, AK, CO, KS, LA, AR. Other aggregators also include NH, GA, and KY as being closer to tossups. Our model here does not seem to incorporate enough uncertainty (for example, the possibility that all of the polls in a given state might be clustered around the wrong value, as happened in NV in 2010)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3(e)\n",
    "\n",
    "Use the posterior distributions in a Monte Carlo simulation to generate election results. In each simulation compute the total number of seats the Republican control. Show a histogram of these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### made up numbers\n",
    "num_states = ests.shape[0]\n",
    "\n",
    "NSIM = 10000\n",
    "simarr = np.zeros(NSIM, dtype=int)\n",
    "for i in xrange(NSIM):\n",
    "    simulated = 30 + np.sum(np.random.normal(ests['mu_post'], scale=ests['sd_post'], size =num_states) > 0 )\n",
    "    simarr[i] = int(simulated)\n",
    "plt.hist(simarr, bins=range(min(simarr)-1, max(simarr)+3))\n",
    "plt.xlabel('Number of Seats in Republican Control')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Monte Carlo simulation of Number of Seats in Republican Control')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "Predict the results for the 2014 Midterm Elections. We will have a three competitions with the terms for scoring entries described above. For both questions below, **explain** or provide commentary on how you arrived at your predictions including code. \n",
    "\n",
    "**Hint**: Use election results from 2010, 2012 to build and test models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4(a)\n",
    "\n",
    "Predict the number of Republican senators. You may provide an interval. Smallest interval that includes the election day result wins. \n",
    "\n",
    "**Note**: we want the total so add the numbers of those that are not up for election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide an explanation of methodology here**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4(b)\n",
    "\n",
    "Predict the R-D difference in each state. The predictions that minimize the residual sum of squares between predicted and observed differences wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide an explanation of methodology here**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4(c)\n",
    "\n",
    "Report a confidence interval for the R-D difference in each state. If the election day result falls outside your confidence interval in more than two states you are eliminated. For those surviving this cutoff, we will add up the size of all confidence intervals and sum. The smallest total length of confidence interval wins. \n",
    "\n",
    "**Note**: you can use Bayesian credible intervals or whatever else you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide an explanation of methodology here**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions\n",
    "\n",
    "To submit your homework, create a folder named **lastname_firstinitial_hw#** and place your IPython notebooks, data files, and any other files in this folder. Your IPython Notebooks should be completely executed with the results visible in the notebook. We should not have to run any code.  Compress the folder (please use .zip compression) and submit to the CS109 dropbox in the appropriate folder. *If we cannot access your work because these directions are not followed correctly, we will not grade your work.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
